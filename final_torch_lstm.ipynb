{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedded_size = 128\n",
    "hidden_size = 150\n",
    "n_classes = 5\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True,\n",
    "                  use_vocab=True,\n",
    "                  tokenize=str.split, \n",
    "                  lower=True,\n",
    "                  batch_first=True,\n",
    "                  fix_length=None)\n",
    "\n",
    "LABEL = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   is_target=True)\n",
    "\n",
    "INDEX = data.Field(sequential=False,\n",
    "                   use_vocab=False,\n",
    "                   is_target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['almost', 'choking', 'much', 'much', 'wanted', 'say', 'strange', 'exclamations', 'came', 'lips', 'pole', 'gazed', 'fixedly', 'bundle', 'notes', 'hand', 'looked', 'odin', 'evident', 'perplexity'], 'label': '3'}\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train_data = TabularDataset(\n",
    "    path = './data/train.nltk.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT), ('label', LABEL)],\n",
    "    skip_header = True)\n",
    "\n",
    "\n",
    "test_data = TabularDataset(\n",
    "    path = './data/test_x.nltk.1.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT), ('index', INDEX)],\n",
    "    skip_header = True)\n",
    "\n",
    "print(vars(train_data[0]))\n",
    "TEXT.build_vocab(train_data, min_freq=7, max_size=20000, vectors = \"fasttext.en.300d\")\n",
    "train_data, valid_data = train_data.split(split_ratio=0.8, stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43903, 10976, 19617)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['joe', 'actually', 'laid', 'head', 'pillow', 'side', 'put', 'arm', 'round', 'neck', 'joy', 'knew'], 'label': '0'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 11985\n"
     ]
    }
   ],
   "source": [
    "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import BucketIterator\n",
    "from torchtext.data import Iterator\n",
    "\n",
    "train_loader, valid_loader = BucketIterator.splits(\n",
    "    (train_data, valid_data),\n",
    "    batch_size = batch_size,\n",
    "    device='cuda:0',\n",
    "    shuffle = True,\n",
    "    sort_key=lambda x:len(x.text),\n",
    "    sort_within_batch=True\n",
    ")\n",
    "test_loader = Iterator(dataset=test_data, batch_size=batch_size, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터의 미니 배치 수 : 1372\n",
      "valid 데이터의 미니 배치 수 : 343\n",
      "test 데이터의 미니 배치 수 : 614\n"
     ]
    }
   ],
   "source": [
    "print('train 데이터의 미니 배치 수 : {}'.format(len(train_loader)))\n",
    "print('valid 데이터의 미니 배치 수 : {}'.format(len(valid_loader)))\n",
    "print('test 데이터의 미니 배치 수 : {}'.format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 embedded_size, \n",
    "                 hidden_size, \n",
    "                 n_classes, \n",
    "                 n_layers=3, \n",
    "                 dropout_p=0.3):\n",
    "        self.input_size = input_size\n",
    "        self.embedded_size = embedded_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        super().__init__()\n",
    "        \n",
    "        # 단순히 숫자로 매칭만 되어있던 것을 neural net에 넣어서 학습시켜줌\n",
    "#         self.emb = nn.Embedding(self.input_size, self.embedded_size) \n",
    "        self.emb = nn.Embedding.from_pretrained(TEXT.vocab.vectors, freeze=False) \n",
    "        self.lstm = nn.LSTM(\n",
    "#             input_size = self.embedded_size,\n",
    "            input_size = 300,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.n_layers,\n",
    "            dropout = self.dropout_p,\n",
    "            batch_first = True,\n",
    "            bidirectional = True\n",
    "        )\n",
    "        self.fc_layer = nn.Linear(hidden_size*2, n_classes)\n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # |x| = (bs, length)\n",
    "#         print(x.shape)\n",
    "\n",
    "        embedded = self.emb(x) \n",
    "        # [embedded] = (bs, length, embedded_size)\n",
    "#         print(embedded.shape)\n",
    "\n",
    "        y, hidden = self.lstm(embedded)\n",
    "        # |y| = (bs, length, hidden_size*2)\n",
    "#         print(\"aa: \", y.shape)\n",
    "#         print(y[:, -1, :].shape)\n",
    "#         print(y[0,:,:])\n",
    "\n",
    "        y = self.fc_layer(y[:, -1, :]) # lstm의 결과중 마지막것만 가져옴\n",
    "#         [y] = (bs, n_classes)\n",
    "#         print(\"bb: \", y.shape)\n",
    "\n",
    "        y = self.activation(y)\n",
    "        # [y] = (bs, n_classes)\n",
    "#         print(\"cc: \", y.shape)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for x, y in train_loader:\n",
    "#     if cnt == 0:\n",
    "#         print(x)\n",
    "#     cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1372/1372 [00:17<00:00, 78.55it/s]\n",
      "  1%|▊                                                                               | 13/1372 [00:00<00:27, 50.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:  1 | train_accuracy: 0.5654 / train_loss: 1.0925 / valid_accuracy: 0.6969 / valid_loss: 0.8154 / best_loss: 0.8154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1372/1372 [00:17<00:00, 79.29it/s]\n",
      "  0%|                                                                                 | 1/1372 [00:00<02:28,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:  2 | train_accuracy: 0.7580 / train_loss: 0.6605 / valid_accuracy: 0.7175 / valid_loss: 0.7578 / best_loss: 0.7578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1372/1372 [00:17<00:00, 79.30it/s]\n",
      "  1%|▍                                                                                | 8/1372 [00:00<00:18, 74.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:  3 | train_accuracy: 0.8179 / train_loss: 0.5042 / valid_accuracy: 0.7279 / valid_loss: 0.7548 / best_loss: 0.7548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1372/1372 [00:17<00:00, 79.10it/s]\n",
      "  0%|▎                                                                                | 5/1372 [00:00<00:32, 42.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:  4 | train_accuracy: 0.8516 / train_loss: 0.4031 / valid_accuracy: 0.7247 / valid_loss: 0.8178 / best_loss: 0.7548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1372/1372 [00:17<00:00, 79.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:  5 | train_accuracy: 0.8783 / train_loss: 0.3312 / valid_accuracy: 0.7198 / valid_loss: 0.9363 / best_loss: 0.7548\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model = LSTM(len(TEXT.vocab), embedded_size, hidden_size, n_classes).to('cuda:0')\n",
    "\n",
    "crit = nn.NLLLoss().to('cuda:0')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "best_loss = 999999\n",
    "best_model = None\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = x.to('cuda:0'), y.to('cuda:0')\n",
    "\n",
    "        y_hat = model(x)\n",
    "        loss = crit(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if isinstance(y, torch.LongTensor) or isinstance(y, torch.cuda.LongTensor):\n",
    "            accuracy = (torch.argmax(y_hat, dim=-1) == y).sum() / float(y.size(0))\n",
    "        else:\n",
    "            accuracy = 0\n",
    "        train_loss += float(loss) / len(train_loader)\n",
    "        train_accuracy += accuracy / len(train_loader)\n",
    "\n",
    "    valid_loss = 0\n",
    "    valid_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to('cuda:0'), y.to('cuda:0')\n",
    "            y_hat = model(x)\n",
    "            loss = crit(y_hat, y)\n",
    "            \n",
    "            if isinstance(y, torch.LongTensor) or isinstance(y, torch.cuda.LongTensor):\n",
    "                accuracy = (torch.argmax(y_hat, dim=-1) == y).sum() / float(y.size(0))\n",
    "            else:\n",
    "                accuracy = 0\n",
    "            valid_loss += float(loss) / len(valid_loader)\n",
    "            valid_accuracy += accuracy / len(valid_loader)\n",
    "            \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_model = deepcopy(model.state_dict())\n",
    "            \n",
    "            \n",
    "    print(\"EPOCHS: {:2d} | train_accuracy: {:.4f} / train_loss: {:.4f} / valid_accuracy: {:.4f} / valid_loss: {:.4f} / best_loss: {:.4f}\".format\n",
    "              (i+1, train_accuracy, train_loss, valid_accuracy, valid_loss, best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, 'rnn_model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('rnn_model1.pth', map_location='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = LSTM(len(TEXT.vocab), embedded_size, hidden_size, n_classes).to('cuda:0')\n",
    "test_model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (emb): Embedding(11985, 300)\n",
       "  (lstm): LSTM(300, 150, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  (fc_layer): Linear(in_features=300, out_features=5, bias=True)\n",
       "  (activation): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 32]\n",
      "\t[.text]:[torch.cuda.LongTensor of size 32x103 (GPU 0)]\n",
      "\t[.index]:[torch.cuda.LongTensor of size 32 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for x in test_loader:\n",
    "    if cnt == 0:\n",
    "        print(x)\n",
    "#         print(x.text.shape)\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.eval()\n",
    "y_hats = []\n",
    "ys = []\n",
    "with torch.no_grad():\n",
    "    for x_batch in test_loader:\n",
    "        x = x_batch.text.to('cuda:0')\n",
    "        idx = x_batch.index\n",
    "        y_hat = test_model(x).cpu()\n",
    "        y_hats += y_hat\n",
    "        ys += idx.cpu()\n",
    "    y_hats = torch.stack(y_hats).exp()\n",
    "    ys = torch.stack(ys)\n",
    "test_pred = y_hats.numpy()\n",
    "idx = ys.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15797, 10467, 16085, ..., 18234, 16864,  4559], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01727097, 0.96136636, 0.00540816, 0.00408278, 0.01187172],\n",
       "       [0.03141812, 0.00749922, 0.05443162, 0.01723714, 0.88941383],\n",
       "       [0.02748302, 0.02230678, 0.03276433, 0.904553  , 0.01289284],\n",
       "       ...,\n",
       "       [0.27242175, 0.09312213, 0.1966439 , 0.26261678, 0.17519534],\n",
       "       [0.04828686, 0.9054456 , 0.01343996, 0.01647181, 0.01635582],\n",
       "       [0.01606853, 0.00126799, 0.00861753, 0.96599245, 0.0080535 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018758</td>\n",
       "      <td>0.148417</td>\n",
       "      <td>0.536296</td>\n",
       "      <td>0.118137</td>\n",
       "      <td>0.178393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046005</td>\n",
       "      <td>0.078767</td>\n",
       "      <td>0.343277</td>\n",
       "      <td>0.130793</td>\n",
       "      <td>0.401158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.521680</td>\n",
       "      <td>0.375053</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.028978</td>\n",
       "      <td>0.020234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032735</td>\n",
       "      <td>0.022664</td>\n",
       "      <td>0.813713</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.125082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.094522</td>\n",
       "      <td>0.045346</td>\n",
       "      <td>0.322157</td>\n",
       "      <td>0.108928</td>\n",
       "      <td>0.429047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19612</th>\n",
       "      <td>0.040261</td>\n",
       "      <td>0.946728</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.005456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19613</th>\n",
       "      <td>0.019459</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.973215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>0.021618</td>\n",
       "      <td>0.946908</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>0.008574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>0.037550</td>\n",
       "      <td>0.691360</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.120103</td>\n",
       "      <td>0.034708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>0.511579</td>\n",
       "      <td>0.031640</td>\n",
       "      <td>0.075890</td>\n",
       "      <td>0.107953</td>\n",
       "      <td>0.272938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19617 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4\n",
       "0      0.018758  0.148417  0.536296  0.118137  0.178393\n",
       "1      0.046005  0.078767  0.343277  0.130793  0.401158\n",
       "2      0.521680  0.375053  0.054054  0.028978  0.020234\n",
       "3      0.032735  0.022664  0.813713  0.005806  0.125082\n",
       "4      0.094522  0.045346  0.322157  0.108928  0.429047\n",
       "...         ...       ...       ...       ...       ...\n",
       "19612  0.040261  0.946728  0.002206  0.005349  0.005456\n",
       "19613  0.019459  0.001162  0.004892  0.001272  0.973215\n",
       "19614  0.021618  0.946908  0.009166  0.013734  0.008574\n",
       "19615  0.037550  0.691360  0.116279  0.120103  0.034708\n",
       "19616  0.511579  0.031640  0.075890  0.107953  0.272938\n",
       "\n",
       "[19617 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(test_pred, index = idx)\n",
    "# df.loc[2]\n",
    "df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sub = pd.read_csv('./data/sample_submission.csv', index_col=0)\n",
    "\n",
    "sub[sub.columns] = df\n",
    "sub.head()\n",
    "sub.to_csv('./data/submission2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test를 shuffle해버림!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
