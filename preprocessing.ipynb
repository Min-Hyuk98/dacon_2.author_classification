{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchtext import data\n",
    "\n",
    "from ignite.engine import Engine\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as stopwords_nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# config = easydict.EasyDict({ \n",
    "#     \"model_fn\": './models/rnn.pth', \n",
    "#     \"train_fn\": './data/train.1.csv',\n",
    "#     \"gpu_id\": 0,\n",
    "#     \"verbose\": 2,\n",
    "#     \"min_vocab_freq\": 5,\n",
    "#     \"max_vocab_size\": 999999,\n",
    "#     \"batch_size\": 128,\n",
    "#     \"n_epochs\": 10,\n",
    "#     \"word_vec_size\": 256,\n",
    "#     \"dropout\": 0.3,\n",
    "#     \"max_length\": 256,\n",
    "#     \"rnn\": True,\n",
    "#     \"hidden_size\": 512,\n",
    "#     \"n_layers\": 4,\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_num(text):\n",
    "    return re.sub(r'[^A-Za-z0-9 ]', '', text)\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stopwords:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n",
    "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
    "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
    "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
    "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
    "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
    "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
    "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
    "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
    "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
    "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "def remove_stopwords_nltk(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    final_text = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stopwords_nltk:\n",
    "            final_text.append(w)\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "stopwords_nltk = set(stopwords_nltk.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv', encoding='utf-8')\n",
    "train['text'] = train['text'].str.lower().apply(alpha_num).apply(remove_stopwords_nltk)\n",
    "train.drop(['index'], axis=1, inplace=True)\n",
    "# train[['author']] = train['author'].apply(lambda x : int(x))\n",
    "train.to_csv('./data/train.nltk.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test_x.csv', encoding='utf-8')\n",
    "test['text'] = test['text'].str.lower().apply(alpha_num).apply(remove_stopwords_nltk)\n",
    "test.drop(['index'], axis=1, inplace=True)\n",
    "# test[['author']] = test['author'].apply(lambda x : int(x))\n",
    "test.to_csv('./data/test_x.nltk.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  author\n",
      "0   almost choking much much wanted say strange ex...       3\n",
      "1                                sister asked suppose       2\n",
      "2   engaged one day walked perusing janes last let...       1\n",
      "3   captain porch keeping carefully way treacherou...       4\n",
      "4   mercy gentlemen odin flung hands dont write an...       3\n",
      "5     well fought said sooth will not charge us twice       4\n",
      "6   not pay impossible considering character will ...       3\n",
      "7   proper figure man atarms said little knight ma...       2\n",
      "8                          not last sunday night said       0\n",
      "9   must not ask cried hell may noble flames known...       4\n",
      "10  unexpected piece luck data coming quickly reas...       2\n",
      "11     one rogue fewer dare say observed master house       4\n",
      "12  scant luggage take london little little posses...       0\n",
      "13  suited odin best think odin one preferred acco...       1\n",
      "14                                    no friends said       4\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./data/train.csv', encoding='utf-8')\n",
    "train['text'] = train['text'].str.lower().apply(alpha_num).apply(remove_stopwords)\n",
    "train.drop(['index'], axis=1, inplace=True)\n",
    "train.to_csv('./data/train.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text\n",
      "0      not think one charming young ladies ever met m...\n",
      "1      no replied sudden consciousness not find canno...\n",
      "2      lady stated intention screaming course screame...\n",
      "3      suddenly silence heard sound sent heart mouth ...\n",
      "4      conviction remained unchanged far knowand beli...\n",
      "...                                                  ...\n",
      "19612  end another day two odin growing visibly stron...\n",
      "19613  afternoon sat together mostly silence watching...\n",
      "19614  odin carried thanks odin proceeded happiness l...\n",
      "19615  soon upon odins leaving room mama said odin al...\n",
      "19616  worse doomed man denouncer wellknown citizen a...\n",
      "\n",
      "[19617 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./data/test_x.csv', encoding='utf-8')\n",
    "test['text'] = test['text'].str.lower().apply(alpha_num).apply(remove_stopwords)\n",
    "test.drop(['index'], axis=1, inplace=True)\n",
    "test.to_csv('./data/test_x.1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
